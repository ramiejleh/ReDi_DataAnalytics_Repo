{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9259035f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc378c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Aim: \n",
    "\n",
    "- To identify and remove errors & duplicate data, in order to create a reliable dataset.\n",
    "- This improves the quality of the training data for analytics and enables accurate decision-making.\n",
    "- Most critical task and commonly said that data scientists spend 80% of their time cleaning and manipulating data and only 20% of their time analyzing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a7a9f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, understand why there are missing values.\n",
    "\n",
    "- Non-Response: Information not filled by subjects, for example, peoples usually don’t like to reveal their salaries, age, mobile number, etc.\n",
    "\n",
    "- Human Error: Data collection is done improperly or mistakes are made in data entry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f42c83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of missing data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7548f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. __Missing Completely At Random (MCAR)__:\n",
    "\n",
    "The data are missing is independent of the observed and unobserved data i.e there is NO RELATIONSHIP between data missing with any other variables/ columns/ features observations within the dataset.\n",
    "\n",
    "For example, When a random sample is taken from the population, where each member has the same chance of being included in the sample. The (unobserved/ not taken) data of members in the population that were not included in the sample are MCAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc0aa1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. __Missing Data Not At Random (MNAR)__:\n",
    "\n",
    "The data are missing is systematically related to the unobserved data i.e there is a RELATIONSHIP between data missing with any other variables/ columns/ features observations within the dataset.\n",
    "\n",
    "For example, in public opinion surveys occurs if those with weaker opinions respond less often.\n",
    "MNAR is the most complex case. Need strategies to handle missing data to find more data about the causes for the missingness or to perform what-if analyses to see how sensitive the results are under various scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbd67f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3. __Missing At Random (MAR)__:\n",
    "\n",
    "The missing data is systematically related to the observed but not the unobserved data i.e probability of missing data for that category is the same. MAR is more general and more realistic than MCAR. Modern missing data methods generally start from the MAR assumption.\n",
    "\n",
    "For example, People usually try to avoid sharing personal data during surveys like most men don’t like to share their salaries, and similarly, women don't like to share their age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae9ab2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bcbe23f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98833709",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0de72e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3486183",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploring the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9076095b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def describe_data(df):\n",
    "    print(\"Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"Rows and Columns:\")\n",
    "    print(df.shape)\n",
    "    print(\"Column Names:\")\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a817c18f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Rows and Columns:\n",
      "(891, 12)\n",
      "Column Names:\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "describe_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d846f82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Understanding Data Attribute Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f10140",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attribute:\n",
    "\n",
    "It can be seen as a data field that represents the characteristics or features of a data object. For a customer, object attributes can be customer Id, address, etc. We can say that a set of attributes used to describe a given object are known as attribute vector or feature vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a789e21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Type of attributes : \n",
    "\n",
    "This is the First step of Data Data-preprocessing. We differentiate between different types of attributes and then preprocess the data. \n",
    "\n",
    "1. Qualitative (Nominal (N), Ordinal (O), Binary(B))\n",
    "2. Quantitative (Numeric, Discrete, Continuous) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b451b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Qualitative Attributes:\n",
    " \n",
    "1. __Nominal Attributes__ – related to names: The values of a Nominal attribute are names of things, some kind of symbols. Values of Nominal attributes represents some category or state and that’s why nominal attribute also referred as categorical attributes and there is no order (rank, position) among values of the nominal attribute. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41f82f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. __Binary Attributes__: Binary data has only 2 values/states. For Example yes or no, affected or unaffected, true or false. \n",
    "\n",
    "    - Symmetric: Both values are equally important (Gender)\n",
    "    - Asymmetric: Both values are not equally important (Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4284bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. __Ordinal Attributes__ :\n",
    "\n",
    "The Ordinal Attributes contains values that have a meaningful sequence or ranking(order) between them, but the magnitude between values is not actually known, the order of values that shows what is important but don’t indicate how important it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27407c66",
   "metadata": {},
   "source": [
    "##### Quantitative Attributes:\n",
    "    \n",
    "1.__Numeric__: A numeric attribute is quantitative because, it is a measurable quantity, represented in integer or real values. Numerical attributes are of 2 types, interval, and ratio. \n",
    "\n",
    "2.__Discrete__ : Discrete data have finite values it can be numerical and can also be in categorical form. These attributes has finite or countably infinite set of values. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db55aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.__Continuous__: Continuous data have an infinite no of states. Continuous data is of float type. There can be many values between 2 and 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0d5512",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        object\n",
       "Sex         object\n",
       "Ticket      object\n",
       "Cabin       object\n",
       "Embarked    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include=['object']).dtypes #Checking the Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9755eeb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Fare           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include=['int','float']).dtypes #Checking the Numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0bdd6ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723415d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## As you explore the features, you can pay attention to any column that:\n",
    "\n",
    "- is formatted poorly,\n",
    "- requires more data or a lot of pre-processing to turn into useful a feature, or\n",
    "- contains redundant information,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c716143",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## To clean the data set, you need to handle missing values \n",
    "because the mathematics underlying most machine learning models assumes that the data is numerical and contains no \n",
    "\n",
    "missing values. Moreover, the scikit-learn library returns an error if you try to train a model like linear regression \n",
    "\n",
    "and logistic regression using data that contain missing or non-numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47394e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70c200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Missing data is perhaps the most common trait of unclean data. These values usually take the form of NaN or None.\n",
    "\n",
    "Here are several causes of missing values: sometimes values are missing because they do not exist, or because of \n",
    "\n",
    "improper collection of data or poor data entry. For example, if someone is underage, and the question applies to \n",
    "\n",
    "people over 18, then the question will contain a missing value. In such cases, it would be wrong to fill in a value \n",
    "\n",
    "for that question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1da08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There are several ways to fill up missing values:\n",
    "\n",
    "- you can remove the lines with the data if you have your data set is big enough and the percentage of missing values is high (over 50%, for example);\n",
    "\n",
    "- you can fill all null variables with 0 is dealing with numerical values;\n",
    "\n",
    "- you can use the Imputerclass from the scikit-learn library to fill in missing values with the data’s (mean, median, most_frequent)\n",
    "\n",
    "- you can also decide to fill up missing values with whatever value comes directly after it in the same column.\n",
    "\n",
    "- These decisions depend on the type of data, what you want to do with the data, and the cause of values missing. In reality, just because something is popular doesn’t necessarily make it the right choice. The most common strategy is to use the mean value, but depending on your data, you may come up with a totally different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d469e49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. __Deleting Rows__\n",
    "\n",
    "This method commonly used to handle the null values. Here, we either delete a particular row if it has a null value for a particular feature and a particular column if it has more than 70-75% of missing values. This method is advised only when there are enough samples in the data set. One has to make sure that after we have deleted the data, there is no addition of bias. Removing the data will lead to loss of information which will not give the expected results while predicting the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10527fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc570c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.dropna(subset=['Embarked'],inplace=True)\n",
    "train1.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b07fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- __Pros__:\n",
    "\n",
    "Complete removal of data with missing values results in robust and highly accurate model\n",
    "Deleting a particular row or a column with no specific information is better, since it does not have a high weightage\n",
    "\n",
    "- __Cons__:\n",
    "\n",
    "Loss of information and data\n",
    "Works poorly if the percentage of missing values is high (say 30%), compared to the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1dc41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Replacing With Mean/Median/Mode\n",
    "\n",
    "This strategy can be applied on a feature which has numeric data like the age of a person or the ticket fare. We can \n",
    "\n",
    "calculate the mean, median or mode of the feature and replace it with the missing values. This is an approximation \n",
    "\n",
    "which can add variance to the data set. But the loss of the data can be negated by this method which yields better \n",
    "\n",
    "results compared to removal of rows and columns. Replacing with the above three approximations are a statistical \n",
    "\n",
    "approach of handling the missing values. This method is also called as leaking the data while training. Another way is \n",
    "\n",
    "to approximate it with the deviation of neighbouring values. This works better if the data is linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26190c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train2 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e04ca35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23741a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56b7515b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2['Age'].replace(np.NaN, train2['Age'].mean()).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fbb57f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2['Age'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f194b19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2['Age'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa46e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Pros:\n",
    "    - This is a better approach when the data size is small\n",
    "    - It can prevent data loss which results in removal of the rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac4f89",
   "metadata": {},
   "source": [
    "- Cons:\n",
    "    - Imputing the approximations add variance and bias\n",
    "    - Works poorly compared to other multiple-imputations method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdc626",
   "metadata": {},
   "source": [
    "- Other, more advanced methods:\n",
    "    - Directional filling (Backwards/Forwards)\n",
    "    - Interpolation\n",
    "    - Extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19f4cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Missing Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "264b8805",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_new = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2630f8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Categories in: \n",
      "Embarked = 4\n",
      "Sex = 2\n",
      "Cabin = 148\n"
     ]
    }
   ],
   "source": [
    "# Code to get number of categories in missing value columns\n",
    "print(\"Number of Categories in: \")\n",
    "\n",
    "for ColName in train_new[['Embarked','Sex','Cabin']]:\n",
    "    print(\"{} = {}\".format(ColName, len(train_new[ColName].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04868b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Frequent Categorical Imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91934a4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Assumptions: Data is Missing At Random (MAR) and missing values look like the majority.\n",
    "- Description: Replacing NAN values with the most frequent occurred category in variable/column.\n",
    "\n",
    "- Implementation:\n",
    "\n",
    "Step 1: Find which category occurred most in each category using mode().\n",
    "\n",
    "Step 2: Replace all NAN values in that column with that category.\n",
    "\n",
    "Step 3: Drop original columns and keep newly imputed columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6d19ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_new1 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6b2dfc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#1. Function to replace NAN values with mode value\n",
    "def impute_nan_most_frequent_category(DataFrame,ColName):\n",
    "    # .mode()[0] - gives first category name\n",
    "     most_frequent_category=DataFrame[ColName].mode()[0]\n",
    "    \n",
    "    # replace nan values with most occured category\n",
    "     DataFrame[ColName + \"_Imputed\"] = DataFrame[ColName]\n",
    "     DataFrame[ColName + \"_Imputed\"].fillna(most_frequent_category,inplace=True)\n",
    "    \n",
    "#2. Call function to impute most occured category\n",
    "for Columns in ['Embarked','Sex','Cabin']:\n",
    "    impute_nan_most_frequent_category(train_new1,Columns)\n",
    "    \n",
    "# Display imputed result\n",
    "train_new1[['Embarked','Embarked_Imputed','Sex','Sex_Imputed','Cabin','Cabin_Imputed']].head(10)\n",
    "#3. Drop actual columns\n",
    "train_new1 = train_new1.drop(['Embarked','Sex','Cabin'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a9c3979",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Imputed</th>\n",
       "      <th>Sex_Imputed</th>\n",
       "      <th>Cabin_Imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>C85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>C123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Embarked_Imputed Sex_Imputed Cabin_Imputed  \n",
       "0         A/5 21171   7.2500                S        male       B96 B98  \n",
       "1          PC 17599  71.2833                C      female           C85  \n",
       "2  STON/O2. 3101282   7.9250                S      female       B96 B98  \n",
       "3            113803  53.1000                S      female          C123  \n",
       "4            373450   8.0500                S        male       B96 B98  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed26c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Advantage: Simple and easy to implement for categorical variables/columns.\n",
    "    \n",
    "- Disadvantage: Features having a max number of null values may bias prediction if replace with the most occurred category. It distorts the relation of the most frequent label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a4160",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Adding a Variable To Capture NAN\n",
    "\n",
    "Assumptions: No assumption, can be work with all type categorical columns.\n",
    "\n",
    "Description: Replace NAN categories with most occurred values, and add a new feature to introduce some weight/importance to non-imputed and imputed observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e41fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation:\n",
    "\n",
    "Step 1. Create a new column and replace 1 if the category is NAN else 0. This column is an importance column to the imputed category.\n",
    "\n",
    "Step 2. Replace NAN value with most occurred category in the actual column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35254de9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_Imputed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sex_Imputed</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Cabin_Imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>E46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked  Embarked_Imputed     Sex  Sex_Imputed    Cabin  Cabin_Imputed\n",
       "0        S                 0    male            0  B96 B98              1\n",
       "1        C                 0  female            0      C85              0\n",
       "2        S                 0  female            0  B96 B98              1\n",
       "3        S                 0  female            0     C123              0\n",
       "4        S                 0    male            0  B96 B98              1\n",
       "5        Q                 0    male            0  B96 B98              1\n",
       "6        S                 0    male            0      E46              0\n",
       "7        S                 0    male            0  B96 B98              1\n",
       "8        S                 0  female            0  B96 B98              1\n",
       "9        C                 0  female            0  B96 B98              1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to impute most occured category and add importance vairable\n",
    "def impute_nan_add_vairable(DataFrame,ColName):\n",
    "    #1. add new column and replace if category is null then 1 else 0\n",
    "    DataFrame[ColName+\"_Imputed\"] =   np.where(DataFrame[ColName].isnull(),1,0)\n",
    "    \n",
    "    # 2. Take most occured category in that vairable (.mode())\n",
    "    \n",
    "    Mode_Category = train[ColName].mode()[0]\n",
    "    \n",
    "    ## 2.1 Replace NAN values with most occured category in actual vairable\n",
    "    \n",
    "    DataFrame[ColName].fillna(Mode_Category,inplace=True)\n",
    "# Call function to impute NAN values and add new importance feature\n",
    "for Columns in ['Embarked','Sex','Cabin']:\n",
    "    impute_nan_add_vairable(train,Columns)\n",
    "    \n",
    "# Display top 10 row to see the result of imputation\n",
    "train[['Embarked','Embarked_Imputed','Sex','Sex_Imputed','Cabin','Cabin_Imputed']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf754f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Advantage: Capture the importance of missingness.\n",
    "    \n",
    "- Disadvantage:\n",
    "\n",
    "Creating Additional Features(Curse of Dimensionality) e.g. if there are 10 columns have null values need to create 10 extra columns.\n",
    "\n",
    "Potentially misunderstood data & the number of missing data should be large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed136192",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Create a New Category (Random Category) for NAN Values\n",
    "\n",
    "Assumptions: No assumption\n",
    "Description: Create a new category for NAN values i.e random category.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "Step 1. Replace NAN value with a new name (here we create a new category as Unknown).\n",
    "\n",
    "Step 2. Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1032e508",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>C85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>C123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q</td>\n",
       "      <td>male</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>E46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>B96 B98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked     Sex    Cabin\n",
       "0        S    male  B96 B98\n",
       "1        C  female      C85\n",
       "2        S  female  B96 B98\n",
       "3        S  female     C123\n",
       "4        S    male  B96 B98\n",
       "5        Q    male  B96 B98\n",
       "6        S    male      E46\n",
       "7        S    male  B96 B98\n",
       "8        S  female  B96 B98\n",
       "9        C  female  B96 B98"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Function to impute null value with new category\n",
    "def impute_nan_create_category(DataFrame,ColName):\n",
    "     DataFrame[ColName] = np.where(DataFrame[ColName].isnull(),\"Unknown\",DataFrame[ColName])\n",
    "## Call function to create new category for variables\n",
    "for Columns in ['Embarked','Sex','Cabin']:\n",
    "    impute_nan_create_category(train,Columns)\n",
    "#2. Display result\n",
    "train[['Embarked','Sex','Cabin']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabeee5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Advantage: \n",
    "\n",
    "Simple and easy to implement for categorical variables/columns and preserves the variance.\n",
    "\n",
    "- Disadvantage:\n",
    "\n",
    "May create random data if the missing category is more.\n",
    "Doesn’t give good results when missing data is a high percentage of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a1bbee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "The above implementation is to explain different ways we can handle missing categorical data. The most widely used methods are Create a New Category (Random Category) for NAN Values and Most frequent category imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743a733",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# pandas.get_dummies() is used for data manipulation. \n",
    "\n",
    "It converts categorical data into dummy or indicator variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910f58f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create Dummies\n",
    "\n",
    "Description: Create dummies or binary type columns for each category in the object/ category type feature. The value for each row is 1 if that category is available in that row else 0. To create dummies use pandas get_dummies() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30b7944e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cat_train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ebe77d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies(cat_train, columns=[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d21961b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original DataFrame is:\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare    Cabin Embarked  Embarked_Imputed  \\\n",
      "0        0         A/5 21171   7.2500  B96 B98        S                 0   \n",
      "1        0          PC 17599  71.2833      C85        C                 0   \n",
      "2        0  STON/O2. 3101282   7.9250  B96 B98        S                 0   \n",
      "3        0            113803  53.1000     C123        S                 0   \n",
      "4        0            373450   8.0500  B96 B98        S                 0   \n",
      "..     ...               ...      ...      ...      ...               ...   \n",
      "886      0            211536  13.0000  B96 B98        S                 0   \n",
      "887      0            112053  30.0000      B42        S                 0   \n",
      "888      2        W./C. 6607  23.4500  B96 B98        S                 0   \n",
      "889      0            111369  30.0000     C148        C                 0   \n",
      "890      0            370376   7.7500  B96 B98        Q                 0   \n",
      "\n",
      "     Sex_Imputed  Cabin_Imputed  \n",
      "0              0              1  \n",
      "1              0              0  \n",
      "2              0              1  \n",
      "3              0              0  \n",
      "4              0              1  \n",
      "..           ...            ...  \n",
      "886            0              1  \n",
      "887            0              0  \n",
      "888            0              1  \n",
      "889            0              0  \n",
      "890            0              1  \n",
      "\n",
      "[891 rows x 15 columns] \n",
      "\n",
      "DataFrame with Dummies:\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name   Age  SibSp  Parch  \\\n",
      "0                              Braund, Mr. Owen Harris  22.0      1      0   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
      "2                               Heikkinen, Miss. Laina  26.0      0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
      "4                             Allen, Mr. William Henry  35.0      0      0   \n",
      "..                                                 ...   ...    ...    ...   \n",
      "886                              Montvila, Rev. Juozas  27.0      0      0   \n",
      "887                       Graham, Miss. Margaret Edith  19.0      0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"   NaN      1      2   \n",
      "889                              Behr, Mr. Karl Howell  26.0      0      0   \n",
      "890                                Dooley, Mr. Patrick  32.0      0      0   \n",
      "\n",
      "               Ticket     Fare    Cabin Embarked  Embarked_Imputed  \\\n",
      "0           A/5 21171   7.2500  B96 B98        S                 0   \n",
      "1            PC 17599  71.2833      C85        C                 0   \n",
      "2    STON/O2. 3101282   7.9250  B96 B98        S                 0   \n",
      "3              113803  53.1000     C123        S                 0   \n",
      "4              373450   8.0500  B96 B98        S                 0   \n",
      "..                ...      ...      ...      ...               ...   \n",
      "886            211536  13.0000  B96 B98        S                 0   \n",
      "887            112053  30.0000      B42        S                 0   \n",
      "888        W./C. 6607  23.4500  B96 B98        S                 0   \n",
      "889            111369  30.0000     C148        C                 0   \n",
      "890            370376   7.7500  B96 B98        Q                 0   \n",
      "\n",
      "     Sex_Imputed  Cabin_Imputed  Sex_female  Sex_male  \n",
      "0              0              1           0         1  \n",
      "1              0              0           1         0  \n",
      "2              0              1           1         0  \n",
      "3              0              0           1         0  \n",
      "4              0              1           0         1  \n",
      "..           ...            ...         ...       ...  \n",
      "886            0              1           0         1  \n",
      "887            0              0           1         0  \n",
      "888            0              1           1         0  \n",
      "889            0              0           0         1  \n",
      "890            0              1           0         1  \n",
      "\n",
      "[891 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"The original DataFrame is:\")\n",
    "print(cat_train, \"\\n\")\n",
    "\n",
    "print(\"DataFrame with Dummies:\")\n",
    "print(sex_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be7c95c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "PassengerId           int64\n",
      "Survived              int64\n",
      "Pclass                int64\n",
      "Name                 object\n",
      "Age                 float64\n",
      "SibSp                 int64\n",
      "Parch                 int64\n",
      "Ticket               object\n",
      "Fare                float64\n",
      "Cabin                object\n",
      "Embarked             object\n",
      "Embarked_Imputed      int64\n",
      "Sex_Imputed           int64\n",
      "Cabin_Imputed         int64\n",
      "Sex_female            uint8\n",
      "Sex_male              uint8\n",
      "dtype: object\n",
      "Rows and Columns:\n",
      "(891, 16)\n",
      "Column Names:\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Embarked_Imputed',\n",
      "       'Sex_Imputed', 'Cabin_Imputed', 'Sex_female', 'Sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "describe_data(sex_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f195de0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Advantage__:\n",
    "    \n",
    "Easy to use and fast way to handle categorical column values.\n",
    "\n",
    "__Disadvantage__:\n",
    "    \n",
    "get_dummies method is not useful when data have many categorical columns.\n",
    "If the category column has many categories leads to add many features into the dataset.\n",
    "Hence, This method is only useful when data having less categorical columns with fewer categories."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
